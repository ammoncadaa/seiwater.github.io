---
title: "Initial Analyses of Climatological Time-Series"
author: '  Manon von Kaenel & Nick Depsky '
layout: post
date: '  Created: August 5th 2016, Updated: August 5th, 2016  '
output:
  html_document:
    number_sections: no
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Some notes for filtering, exploring, and conducting some basic statistical analyses on raw climate data from local station observations using R. This script was originally written in the context of preparing climate input data for a WEAP model, and is a good initial step in this process. 

SEI R-users group

The Rmarkdown file and data used to generate this page is stored on [github](https://github.com/manonvk/Climate-Data-Processing-for-WEAP-Applications/tree/master/R)

## Goals 
Go over some common workflows relevant to exploring, filtering, and correcting climate station data. The goals of these initial analyses of climatological time-series are to familiarize yourself with your climate data; specifically, to:

* Understand the __spatial distribution__ of your climate stations
* Understand the __temporal distribution__ of the observed climate measurements
* Understand the __statistical variability__ of the observed climate measurements 

The knowledge and understanding generated by these analyses can inform the following workflows:

* Subsetting data to designated period of record and selected stations
* Identifying and removing incorrect and extreme data values
* [Filling in missing data](https://njdepsky.github.io/FillMissData1.html)

This example will use precipitation and temperature records from the Chancay Lambayeque watershed, Peru.  

## Resources
Data used for the examples are hosted in this repository. The zipped file contains the following:
    - `Table_All_Precip.csv` : csv of daily precipitation data (unfiltered) from climate stations in and surrounding the Chancay-Lambayeque   watershed, Peru
    - `Table_All_Temp_Max.csv`: csv of daily maximum temperature data (unfiltered) from same stations
    - `Table_All_Temp_Min.csv`: csv of daily minimum temperature data (unfiltered) from same stations
    - `Coordinates.csv`: csv of lat-long coordinates of local climate stations
    - `Proyecto_CuencaCL.shp`: shapefile (including related files) of study site extent

You can download/unzip the data by hand or run the following code to download and unzip the data to a temporary directory.

```{r eval = FALSE}
setwd( tempdir() )  # set working directory to temporary directory 
download.file("https://github.com/manonvk/Climate-Data-Processing-for-WEAP-Applications/blob/master/Raw-Data/rawclimatedataR.zip", destfile = 'rawclimatedataR.zip')
unzip( 'rawclimatedataR.zip' , exdir = '.')
```

# 0. Prerequisites
Some functions we will use come the following packages, so be sure to have them installed prior to attempting this exercise. 

*`ggmap`: mapping functions
*`ggplot2`: graphing functions
*`raster`: opening shapefiles
*`rgdal`: managing shapefiles and coordinates data
*

You can download these packages with...

```{r eval=FALSE}
install.packages('ggmap', repos = "http://cran.cnr.berkeley.edu/")
install.packages('ggplot2', repos = "http://cran.cnr.berkeley.edu/")
install.packages('raster', repos = "http://cran.cnr.berkeley.edu/")
install.packages('rgdal', repos = "http://cran.cnr.berkeley.edu/")

```

# 1. Get the data in

First, let's get all the data you'll need for this script loaded and saved. 

__Packages you'll need:__

```{r}
library(ggmap)
library(ggplot2)
library(raster)
library(rgdal)

```

__Loading the CSV files for precipitation and temperature (min and max) station records, and the station coordinates:__

```{r}
#Precip <- read.csv('Table_All_Precip.csv', check.names = F, stringsAsFactors = F)
#Temp_Min <- read.csv('Table_All_Temp_Min.csv', check.names = F, stringsAsFactors = F)
#Temp_Max <- read.csv('Table_All_Temp_Max.csv', check.names = F, stringsAsFactors = F)
#Coordinates <- read.csv('Coordinates.csv', check.names = F, stringsAsFactors = F)
```

that was easy!

As a side note, the 'check.names = F' parameter in the 'read.csv' function preserves the column headers from the original record table. Your input climate tables should look like this:
```{r}
#head(Precip)
```

And the coordinate table should look like this, with spatial information saved in lat and long coordinates: 
```{r}
#head(Coordinates)
```
__Loading your shapefile:__

```{r}
#project <- readOGR( tempdir(),'Proyecto_CuencaCL') 
```

Make sure your shapefile is saved with the WGS84 reference system. You will only use this shapefile when creating your Station Map.


# 2. Temporal Distribution

Let's first look at the __temporal__ distribution of your data; that is, the period of record for each climate variable at each station. This will help us assess the amount of missing data we are dealing with, and designate an optimal period of record for your project.

## Plot a Period of Record Graph


# 3. Spatial Distribution

Now, let's take a look at how the stations are __spatially distributed__ within your study site, and explore which stations have precipitation and/or temperature data available within any designated period of record. This will help us assess the availability of data in a spatial sense, again informing what an optimal period of record may be, and helping to inform us about any holes in data that may affect future workflows and analyses.

## Create a Station Map

# 4. Statistical Variability

The third lens through which to view your climate data is __statistically__; that is, looking at the climate measurements themselves. We will be plotting the time-series graphs for precipitation, minimum temperature, and maximum temperature at each of your stations individually, as well as on a single plot. We will also calculate basic statistical indicators for each time series: average, standard deviation, minimum, maximum, and percent of missing data. This portion of the script can be iterative: that is, you can come back to and re-run this script after correcting your data, and/or after filling in missing data, to better visualize and understand the data.

## Plot time-series graphs of each of your climate stations

## Plot single time-series for each climate variable

## Calculate basic statistical indicators for each time series

* Average, standard deviation, minimum, and maximum
* Percent of missing data values

# 5. Subset your data

Armed with the knowledge and understanding you've gained about your data, let's move on to subsetting your data to a designated period of record, and to the final stations you want to include in the next steps of your analysis.

# 6. Identifying and removing errors & extremes

## Eliminate negative precipitation values and all nonnumeric climate measurements
## Identifies and removes user-defined "extreme" climate measurements
## Identifies errors in which minimum daily temperature is greater than maximum daily temperature

# 7. Filling in missing data

This workflow is described in detail at the following [link](https://njdepsky.github.io/FillMissData1.html).

